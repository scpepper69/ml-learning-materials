{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scpepper69/ml-learning-materials/blob/master/Tensorflow_Objectetection_M2Det_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9343mSGosak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### Download MSCOCO 2017 DataSet \n",
        "# !!! Attentioin !!! Images zip is over 19Gbyte. It takes about 20 minutes at Google Colboratory.\n",
        "\n",
        "# Train Images\n",
        "!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!unzip -q train2017.zip\n",
        "\n",
        "# Validatioin Images\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip -q val2017.zip\n",
        "\n",
        "# Test Images\n",
        "#!wget http://images.cocodataset.org/zips/test2017.zip\n",
        "#!unzip -q test2017.zip\n",
        "\n",
        "# Annotations\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip -q annotations_trainval2017.zip\n",
        "\n",
        "!mkdir output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItwcqTmjo2o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### DataSet Label Matching\n",
        "mscoco2017 = {\n",
        "    1: [0, 'person'],\n",
        "    2: [1, 'bicycle'],\n",
        "    3: [2, 'car'],\n",
        "    4: [3, 'motorcycle'],\n",
        "    5: [4, 'airplane'],\n",
        "    6: [5, 'bus'],\n",
        "    7: [6, 'train'],\n",
        "    8: [7, 'truck'],\n",
        "    9: [8, 'boat'],\n",
        "    10: [9, 'traffic light'],\n",
        "    11: [10, 'fire hydrant'],\n",
        "    13: [11, 'stop sign'],\n",
        "    14: [12, 'parking meter'],\n",
        "    15: [13, 'bench'],\n",
        "    16: [14, 'bird'],\n",
        "    17: [15, 'cat'],\n",
        "    18: [16, 'dog'],\n",
        "    19: [17, 'horse'],\n",
        "    20: [18, 'sheep'],\n",
        "    21: [19, 'cow'],\n",
        "    22: [20, 'elephant'],\n",
        "    23: [21, 'bear'],\n",
        "    24: [22, 'zebra'],\n",
        "    25: [23, 'giraffe'],\n",
        "    27: [24, 'backpack'],\n",
        "    28: [25, 'umbrella'],\n",
        "    31: [26, 'handbag'],\n",
        "    32: [27, 'tie'],\n",
        "    33: [28, 'suitcase'],\n",
        "    34: [29, 'frisbee'],\n",
        "    35: [30, 'skis'],\n",
        "    36: [31, 'snowboard'],\n",
        "    37: [32, 'sports ball'],\n",
        "    38: [33, 'kite'],\n",
        "    39: [34, 'baseball bat'],\n",
        "    40: [35, 'baseball glove'],\n",
        "    41: [36, 'skateboard'],\n",
        "    42: [37, 'surfboard'],\n",
        "    43: [38, 'tennis racket'],\n",
        "    44: [39, 'bottle'],\n",
        "    46: [40, 'wine glass'],\n",
        "    47: [41, 'cup'],\n",
        "    48: [42, 'fork'],\n",
        "    49: [43, 'knife'],\n",
        "    50: [44, 'spoon'],\n",
        "    51: [45, 'bowl'],\n",
        "    52: [46, 'banana'],\n",
        "    53: [47, 'apple'],\n",
        "    54: [48, 'sandwich'],\n",
        "    55: [49, 'orange'],\n",
        "    56: [50, 'broccoli'],\n",
        "    57: [51, 'carrot'],\n",
        "    58: [52, 'hot dog'],\n",
        "    59: [53, 'pizza'],\n",
        "    60: [54, 'donut'],\n",
        "    61: [55, 'cake'],\n",
        "    62: [56, 'chair'],\n",
        "    63: [57, 'couch'],\n",
        "    64: [58, 'potted plant'],\n",
        "    65: [59, 'bed'],\n",
        "    67: [60, 'dining table'],\n",
        "    70: [61, 'toilet'],\n",
        "    72: [62, 'tv'],\n",
        "    73: [63, 'laptop'],\n",
        "    74: [64, 'mouse'],\n",
        "    75: [65, 'remote'],\n",
        "    76: [66, 'keyboard'],\n",
        "    77: [67, 'cell phone'],\n",
        "    78: [68, 'microwave'],\n",
        "    79: [69, 'oven'],\n",
        "    80: [70, 'toaster'],\n",
        "    81: [71, 'sink'],\n",
        "    82: [72, 'refrigerator'],\n",
        "    84: [73, 'book'],\n",
        "    85: [74, 'clock'],\n",
        "    86: [75, 'vase'],\n",
        "    87: [76, 'scissors'],\n",
        "    88: [77, 'teddy bear'],\n",
        "    89: [78, 'hair drier'],\n",
        "    90: [79, 'toothbrush'],\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRSzkcYFo5jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Prepare Libraries\n",
        "# from Prepare DataSet\n",
        "import argparse\n",
        "import json\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# from M2Det Class\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "#from utils.layer import *\n",
        "\n",
        "# from Data Class\n",
        "import cv2\n",
        "import glob\n",
        "#import os\n",
        "import multiprocessing\n",
        "import time\n",
        "#import numpy as np\n",
        "#from utils.generate_priors import generate_priors\n",
        "#from utils.assign_boxes import assign_boxes\n",
        "#from utils.augment import augment\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOkHgYVEo7ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare MSCOCO 2017 DataSet for Training\n",
        "\n",
        "def prerape_mscoco(image_dir, annotation_path, output_dir):\n",
        "    with open(annotation_path) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    annotations = data['annotations']\n",
        "    for annotation in annotations:\n",
        "        catid = annotation['category_id']\n",
        "        clsid = mscoco2017[catid][0]\n",
        "        \n",
        "        image_filename = '{0:012d}'.format(annotation['image_id']) + '.jpg'\n",
        "        src = os.path.join(image_dir, image_filename)\n",
        "        if not os.path.exists(src):\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(src)\n",
        "        h, w = img.shape[:2]\n",
        "        bbox = annotation['bbox']\n",
        "        x1 = bbox[0] / w\n",
        "        y1 = bbox[1] / h\n",
        "        x2 = (bbox[0] + bbox[2]) / w\n",
        "        y2 = (bbox[1] + bbox[3]) / h\n",
        "\n",
        "        label = [str(clsid), str(x1), str(y1), str(x2), str(y2)]\n",
        "\n",
        "        output_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
        "        dst = os.path.join(output_dir, output_filename)\n",
        "        with open(dst, 'a') as f:\n",
        "            f.write('\\t'.join(label) + '\\n')\n",
        "#        print(label, src)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF908r3EpCSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prerape_mscoco(image_dir=\"./train2017\", annotation_path='./annotations/image_info_unlabeled2017.json', output_dir=\"./output\" )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX7idO2p7YJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EicFnwH7bLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################\n",
        "# M2Det Model Class\n",
        "##################################################\n",
        "class M2Det:\n",
        "    def __init__(self, inputs, is_training, num_classes, use_sfam=False):\n",
        "        self.num_classes = num_classes + 1 # for background class\n",
        "        self.use_sfam = use_sfam\n",
        "        self.levels = 8\n",
        "        self.scales = 6\n",
        "        self.num_priors = 9\n",
        "        self.build(inputs, is_training)\n",
        "\n",
        "    def build(self, inputs, is_training):\n",
        "        with tf.variable_scope('VGG16'):\n",
        "            net = inputs\n",
        "            net = vgg_layer(net, is_training, 64, 2)\n",
        "            net = vgg_layer(net, is_training, 128, 2)\n",
        "            net = vgg_layer(net, is_training, 256, 3)\n",
        "            net = vgg_layer(net, is_training, 512, 3, pooling=False)\n",
        "            feature1 = net\n",
        "            net = vgg_layer(net, is_training, 1024, 3)\n",
        "            feature2 = net\n",
        "\n",
        "        with tf.variable_scope('M2Det'):\n",
        "            with tf.variable_scope('FFMv1'):\n",
        "                feature1 = conv2d_layer(feature1, filters=256, kernel_size=3, strides=1)\n",
        "                feature1 = tf.nn.relu(batch_norm(feature1, is_training))\n",
        "                feature2 = conv2d_layer(feature2, filters=512, kernel_size=1, strides=1)\n",
        "                feature2 = tf.nn.relu(batch_norm(feature2, is_training))\n",
        "                feature2 = tf.image.resize_images(feature2, tf.shape(feature1)[1:3], \n",
        "                                                  method=tf.image.ResizeMethod.BILINEAR)\n",
        "                base_feature = tf.concat([feature1, feature2], axis=3)\n",
        "\n",
        "            outs = []\n",
        "            for i in range(self.levels):\n",
        "                if i == 0:\n",
        "                    net = conv2d_layer(base_feature, filters=256, kernel_size=1, strides=1)\n",
        "                    net = tf.nn.relu(batch_norm(net, is_training))\n",
        "                else:\n",
        "                    with tf.variable_scope('FFMv2_{}'.format(i+1)):\n",
        "                        net = conv2d_layer(base_feature, filters=128, kernel_size=1, strides=1)\n",
        "                        net = tf.nn.relu(batch_norm(net, is_training))\n",
        "                        net = tf.concat([net, out[-1]], axis=3)\n",
        "                with tf.variable_scope('TUM{}'.format(i+1)):\n",
        "                    out = tum(net, is_training, self.scales)\n",
        "                outs.append(out)\n",
        "\n",
        "            features = []\n",
        "            for i in range(self.scales):\n",
        "                feature = tf.concat([outs[j][i] for j in range(self.levels)], axis=3)\n",
        "\n",
        "                if self.use_sfam:\n",
        "                    with tf.variable_scope('SFAM'):\n",
        "                        attention = tf.reduce_mean(feature, axis=[1, 2], keepdims=True)\n",
        "                        attention = tf.layers.dense(inputs=attention, units=64, \n",
        "                                                    activation=tf.nn.relu, name='fc1_{}'.format(i+1))\n",
        "                        attention = tf.layers.dense(inputs=attention, units=1024,\n",
        "                                                    activation=tf.nn.sigmoid, name='fc2_{}'.format(i+1))\n",
        "                        feature = feature * attention\n",
        "\n",
        "                features.insert(0, feature)\n",
        "\n",
        "            all_cls = []\n",
        "            all_reg = []\n",
        "            with tf.variable_scope('prediction'):\n",
        "                for i, feature in enumerate(features):\n",
        "                    print(i+1, feature.shape)\n",
        "                    cls = conv2d_layer(feature, self.num_priors * self.num_classes, 3, 1, use_bias=True)\n",
        "                    cls = batch_norm(cls, is_training) # activation function is identity\n",
        "                    cls = flatten_layer(cls)\n",
        "                    all_cls.append(cls)\n",
        "                    reg = conv2d_layer(feature, self.num_priors * 4, 3, 1, use_bias=True)\n",
        "                    reg = batch_norm(reg, is_training) # activation function is identity\n",
        "                    reg = flatten_layer(reg)\n",
        "                    all_reg.append(reg)\n",
        "                all_cls = tf.concat(all_cls, axis=1)\n",
        "                all_reg = tf.concat(all_reg, axis=1)\n",
        "                num_boxes = int(all_reg.shape[-1].value / 4)\n",
        "                all_cls = tf.reshape(all_cls, [-1, num_boxes, self.num_classes])\n",
        "                all_cls = tf.nn.softmax(all_cls)\n",
        "                all_reg = tf.reshape(all_reg, [-1, num_boxes, 4])\n",
        "                self.prediction = tf.concat([all_reg, all_cls], axis=-1)\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#    inputs = tf.placeholder(tf.float32, [None, 320, 320, 3])\n",
        "#    is_training = tf.constant(False)\n",
        "#    num_classes = 80\n",
        "#    m2det = M2Det(inputs, is_training, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9NZzSauikJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################\n",
        "# utils/generate_priors.py\n",
        "##################################################\n",
        "def generate_priors(num_scales=3, anchor_scale=2.0, image_size=320, shapes=[40, 20, 10, 5, 3, 1]):\n",
        "    anchor_configs = {}\n",
        "    for shape in shapes:\n",
        "        anchor_configs[shape] = []\n",
        "        for scale_octave in range(num_scales):\n",
        "            for aspect_ratio in [(1, 1), (1.41, 0.71), (0.71, 1.41)]:\n",
        "                anchor_configs[shape].append(\n",
        "                    (image_size / shape, scale_octave / float(num_scales), aspect_ratio))\n",
        "\n",
        "    boxes_all = []\n",
        "    for _, configs in anchor_configs.items():\n",
        "        boxes_level = []\n",
        "        for config in configs:\n",
        "            stride, octave_scale, aspect = config\n",
        "            base_anchor_size = anchor_scale * stride * (2 ** octave_scale)\n",
        "            anchor_size_x_2 = base_anchor_size * aspect[0] / 2.0\n",
        "            anchor_size_y_2 = base_anchor_size * aspect[1] / 2.0\n",
        "            x = np.arange(stride / 2, image_size, stride)\n",
        "            y = np.arange(stride / 2, image_size, stride)\n",
        "            xv, yv = np.meshgrid(x, y)\n",
        "            xv = xv.reshape(-1)\n",
        "            yv = yv.reshape(-1)\n",
        "            boxes = np.vstack((yv - anchor_size_y_2, xv - anchor_size_x_2,\n",
        "                               yv + anchor_size_y_2, xv + anchor_size_x_2))\n",
        "            boxes = np.swapaxes(boxes, 0, 1)\n",
        "            boxes_level.append(np.expand_dims(boxes, axis=1))\n",
        "        boxes_level = np.concatenate(boxes_level, axis=1)\n",
        "        boxes_level /= image_size\n",
        "        boxes_all.append(boxes_level.reshape([-1, 4]))\n",
        "\n",
        "    anchor_boxes = np.vstack(boxes_all)\n",
        "\n",
        "    return anchor_boxes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI4qUbVqinhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################\n",
        "# utils/assign_boxes.py\n",
        "##################################################\n",
        "def encode_box(box, priors, assignment_threshold):\n",
        "    inter_upleft = np.maximum(priors[:, :2], box[:2])\n",
        "    inter_botright = np.minimum(priors[:, 2:], box[2:])\n",
        "    inter_wh = np.maximum(inter_botright - inter_upleft, 0)\n",
        "    inter = inter_wh[:, 0] * inter_wh[:, 1]\n",
        "    area_pred = (box[2] - box[0]) * (box[3] - box[1])\n",
        "    area_gt = (priors[:, 2] - priors[:, 0])\n",
        "    area_gt *= (priors[:, 3] - priors[:, 1])\n",
        "    union = area_pred + area_gt - inter\n",
        "    iou = inter / union\n",
        "\n",
        "    encoded_box = np.zeros((len(priors), 5))\n",
        "    assign_mask = iou >= assignment_threshold\n",
        "    encoded_box[:, -1][assign_mask] = iou[assign_mask]\n",
        "    assigned_priors = priors[assign_mask] \n",
        "    box_center = 0.5 * (box[:2] + box[2:])\n",
        "    box_wh = box[2:] - box[:2]\n",
        "    assigned_priors_center = 0.5 * (assigned_priors[:, :2] + assigned_priors[:, 2:])\n",
        "    assigned_priors_wh = (assigned_priors[:, 2:4] - assigned_priors[:, :2])\n",
        "\n",
        "    encoded_box[:, :2][assign_mask] = box_center - assigned_priors_center\n",
        "    encoded_box[:, :2][assign_mask] /= assigned_priors_wh\n",
        "    encoded_box[:, :2][assign_mask] /= 0.1 # variance0\n",
        "    encoded_box[:, 2:4][assign_mask] = np.log(box_wh / assigned_priors_wh)\n",
        "    encoded_box[:, 2:4][assign_mask] /= 0.2 # variance1\n",
        "    return encoded_box.ravel()\n",
        "\n",
        "def assign_boxes(boxes, priors, num_classes, threshold=0.5):\n",
        "    num_classes += 1 # add background class\n",
        "    assignment = np.zeros((len(priors), 4 + num_classes + 1))\n",
        "    assignment[:, 4] = 1.0 # background\n",
        "    encoded_boxes = np.apply_along_axis(encode_box, 1, boxes[:, :4], priors, threshold)\n",
        "    encoded_boxes = encoded_boxes.reshape(-1, len(priors), 5)\n",
        "    best_iou = encoded_boxes[:, :, -1].max(axis=0)\n",
        "    best_iou_idx = encoded_boxes[:, :, -1].argmax(axis=0)\n",
        "    best_iou_mask = best_iou > 0 # judge by iou between prior and bbox\n",
        "    best_iou_idx = best_iou_idx[best_iou_mask]\n",
        "    assign_num = len(best_iou_idx)\n",
        "    encoded_boxes = encoded_boxes[:, best_iou_mask, :]\n",
        "    assignment[:, :4][best_iou_mask] = encoded_boxes[best_iou_idx, np.arange(assign_num), :4]\n",
        "    assignment[:, 4][best_iou_mask] = 0 # background\n",
        "    assignment[:, 5:-1][best_iou_mask] = boxes[best_iou_idx, 4:]\n",
        "    assignment[:, -1][best_iou_mask] = 1 # objectness\n",
        "    return assignment\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY79n3t7iqQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################\n",
        "# utils/augment.py\n",
        "##################################################\n",
        "def normalize(img):\n",
        "    img = (img - 127.5) / 128.0\n",
        "    return img\n",
        "\n",
        "def random_crop(img, boxes):\n",
        "    if np.random.uniform() > 0.5:\n",
        "        return img, boxes\n",
        "\n",
        "    x1, x2, y1, y2 = np.random.uniform(low=0.0, high=0.20, size=4)\n",
        "    img_h, img_w = img.shape[:2]\n",
        "\n",
        "    p1 = int(x1 * img_w)\n",
        "    p2 = int((1.0 - x2) * img_w)\n",
        "    q1 = int(y1 * img_h)\n",
        "    q2 = int((1.0 - y2) * img_h)\n",
        "    img = img[q1:q2, p1:p2, :]\n",
        "\n",
        "    cropped_boxes = []\n",
        "    for box in boxes:\n",
        "        xmin, ymin, xmax, ymax = box[:4]\n",
        "        if ((x1 >= xmax) or (xmin >= 1.0 - x2) or (y1 >= ymax) or (ymin >= 1.0 - y2)):\n",
        "            continue\n",
        "        xmin = max((xmin - x1) / (1.0 - x1 - x2), 0.0)\n",
        "        xmax = 1.0 - max((1.0 - xmax - x2) / (1.0 - x1 - x2), 0.0)\n",
        "        ymin = max((ymin - y1) / (1.0 - y1 - y2), 0.0)\n",
        "        ymax = 1.0 - max((1.0 - ymax - y2) / (1.0 - y1 - y2), 0.0)\n",
        "        box = [xmin, ymin, xmax, ymax] + box[4:]\n",
        "        cropped_boxes.append(box)\n",
        "\n",
        "    return img, cropped_boxes\n",
        "\n",
        "def random_flip(img, boxes):\n",
        "    if np.random.uniform() > 0.5:\n",
        "        img = cv2.flip(img, 1)\n",
        "        flipped_boxes = []\n",
        "        for box in boxes:\n",
        "            xmin, ymin, xmax, ymax = box[:4]\n",
        "            new_xmin = 1.0 - xmax\n",
        "            new_xmax = 1.0 - xmin\n",
        "            box = [new_xmin, ymin, new_xmax, ymax] + box[4:]\n",
        "            flipped_boxes.append(box)\n",
        "    else:\n",
        "        flipped_boxes = boxes\n",
        "\n",
        "    return img, flipped_boxes\n",
        "\n",
        "def down_sample(img):\n",
        "    img_h, img_w = img.shape[:2]\n",
        "    k = max(int(np.random.normal(loc=2.0)), 1)\n",
        "    if k > 1:\n",
        "        img = cv2.resize(img, (int(img_w / k), int(img_h / k)), interpolation=cv2.INTER_CUBIC)\n",
        "        img = cv2.resize(img, (img_w, img_h), interpolation=cv2.INTER_CUBIC)\n",
        "    return img\n",
        "\n",
        "def multi_scale(img, boxes):\n",
        "    if np.random.uniform() > 0.5:\n",
        "        return img, boxes\n",
        "\n",
        "    img_h, img_w = img.shape[:2]\n",
        "    margin_left = int(min(max(np.random.normal(), 0.0), 0.5) * img_w)\n",
        "    margin_right = int(min(max(np.random.normal(), 0.0), 0.5) * img_w)\n",
        "    margin_top = int(min(max(np.random.normal(loc=0.1), 0.0), 0.5) * img_h)\n",
        "    margin_bottom = int(min(max(np.random.normal(loc=0.1), 0.0), 0.5) * img_h)\n",
        "    new_w = img_w + margin_left + margin_right\n",
        "    new_h = img_h + margin_top + margin_bottom\n",
        "    x1 = margin_left\n",
        "    x2 = margin_left + img_w\n",
        "    y1 = margin_top\n",
        "    y2 = margin_top + img_h\n",
        "    out = np.ones((new_h, new_w, 3), dtype=np.uint8) * 127\n",
        "    out[y1:y2, x1:x2, :] = img\n",
        "\n",
        "    scaled_boxes = []\n",
        "    for box in boxes:\n",
        "        xmin, ymin, xmax, ymax = box[:4]\n",
        "        xmin = ((margin_left + xmin * img_w) / new_w)\n",
        "        xmax = ((margin_left + xmax * img_w) / new_w)\n",
        "        ymin = ((margin_top + ymin * img_h) / new_h)\n",
        "        ymax = ((margin_top + ymax * img_h) / new_h)\n",
        "        box = [xmin, ymin, xmax, ymax] + box[4:]\n",
        "        scaled_boxes.append(box)\n",
        "\n",
        "    return out, scaled_boxes\n",
        "\n",
        "def scale(img, labels, img_size):\n",
        "    img_h, img_w = img.shape[:2]\n",
        "    ratio = max(img_h, img_w) / img_size\n",
        "    new_h = int(img_h / ratio)\n",
        "    new_w = int(img_w / ratio)\n",
        "    ox = (img_size - new_w) // 2\n",
        "    oy = (img_size - new_h) // 2\n",
        "    scaled = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "    out = np.ones((img_size, img_size, 3), dtype=np.uint8) * 127\n",
        "    out[oy:oy + new_h, ox:ox + new_w, :] = scaled\n",
        "\n",
        "    scaled_labels = []\n",
        "    for label in labels:\n",
        "        xmin, ymin, xmax, ymax = label[0:4]\n",
        "        xmin = (xmin * new_w + ox) / img_size\n",
        "        ymin = (ymin * new_h + oy) / img_size\n",
        "        xmax = (xmax * new_w + ox) / img_size\n",
        "        ymax = (ymax * new_h + oy) / img_size\n",
        "        label = [xmin, ymin, xmax, ymax] + label[4:]\n",
        "        scaled_labels.append(label)\n",
        "\n",
        "    return out, scaled_labels\n",
        "\n",
        "def augment(img, boxes, input_size):\n",
        "    img, boxes = random_crop(img, boxes)\n",
        "    img, boxes = random_flip(img, boxes)\n",
        "    #img, boxes = multi_scale(img, boxes)\n",
        "    #img = down_sample(img)\n",
        "    img, boxes = scale(img, boxes, input_size)\n",
        "    img = normalize(img)\n",
        "    return img, boxes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF0h-tKBiulP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################################\n",
        "# Data Class\n",
        "##################################################\n",
        "class Data:\n",
        "    def __init__(self, image_dir, label_dir, num_classes, input_size, shapes, assignment_threshold):\n",
        "        self.image_dir = image_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.num_classes = num_classes \n",
        "        self.input_size = input_size\n",
        "        self.assignment_threshold = assignment_threshold\n",
        "        self.priors = generate_priors(image_size=self.input_size, shapes=shapes)\n",
        "        self.size = self.get_size()\n",
        "\n",
        "    def start(self):\n",
        "        self.q = multiprocessing.Queue()\n",
        "        p = multiprocessing.Process(target=self.put, args=(self.q,))\n",
        "        p.start()\n",
        "\n",
        "    def get_paths(self):\n",
        "        paths = []\n",
        "        for bb_path in glob.glob(os.path.join(self.label_dir, '*.txt')):\n",
        "            im_path = os.path.join(self.image_dir, os.path.splitext(os.path.basename(bb_path))[0] + '.jpg')\n",
        "            if os.path.exists(im_path):\n",
        "                paths.append([im_path, bb_path])\n",
        "        return paths\n",
        "\n",
        "    def get_size(self):\n",
        "        return len(self.get_paths())\n",
        "\n",
        "    def put(self, q):\n",
        "        queue_max_size = 1000\n",
        "        paths = []\n",
        "        while True:\n",
        "            if len(paths) == 0:\n",
        "                paths = self.get_paths()\n",
        "            if q.qsize() >= queue_max_size:\n",
        "                time.sleep(0.1)\n",
        "                continue\n",
        "\n",
        "            ix = np.random.randint(0, len(paths))\n",
        "            path = paths.pop(ix)\n",
        "            im_path, bb_path = path\n",
        "            npimg = np.fromfile(im_path, dtype=np.uint8)\n",
        "            img = cv2.imdecode(npimg, cv2.IMREAD_COLOR)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            with open(bb_path) as f:\n",
        "                lines = f.read().splitlines()\n",
        "\n",
        "            boxes = []\n",
        "            for line in lines:\n",
        "                ix, xmin, ymin, xmax, ymax = line.split('\\t') \n",
        "                onehot_label = np.eye(self.num_classes)[int(ix)]\n",
        "                box = [float(xmin), float(ymin), float(xmax), float(ymax)] + onehot_label.tolist()\n",
        "                boxes.append(box)\n",
        "\n",
        "            img, boxes = augment(img, boxes, self.input_size)\n",
        "\n",
        "            if len(boxes) == 0:\n",
        "                continue\n",
        "            boxes = np.array(boxes)\n",
        "            assignment = assign_boxes(boxes, self.priors, self.num_classes, self.assignment_threshold)\n",
        "            q.put([img, assignment])\n",
        "            \n",
        "    def get(self, batch_size):\n",
        "        x_batch = []\n",
        "        t_batch = []\n",
        "        for _ in range(batch_size):\n",
        "            while True:\n",
        "                if self.q.qsize() == 0:\n",
        "                    time.sleep(1)\n",
        "                    continue\n",
        "                img, assignment = self.q.get()\n",
        "                x_batch.append(img)\n",
        "                t_batch.append(assignment)\n",
        "                break\n",
        "        return np.asarray(x_batch), np.asarray(t_batch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}